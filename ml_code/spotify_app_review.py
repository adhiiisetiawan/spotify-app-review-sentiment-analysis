# -*- coding: utf-8 -*-
"""Spotify App Review

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yb3Urk3NxXqIcvcjZwv1zSMhe_J-y4jJ
"""

from google.colab import files

files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download 'mfaaris/spotify-app-reviews-2022'
!unzip 'spotify-app-reviews-2022.zip'

import datetime, json, os

import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

df = pd.read_csv('reviews.csv')
df.head()

def get_sentiment(rating):
    if rating == 1 or rating == 2 or rating == 3:
        return 0
    if rating == 4 or rating == 5:
        return 1


df["Sentiment"] = df["Rating"].apply(get_sentiment)

df.head()

df = df.drop(columns=['Time_submitted', 'Rating', 'Total_thumbsup', 'Reply'])
df.head()

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

df["Review"] = df["Review"].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words if word.isalpha()))

df.head()

review = df['Review'].values
label = df['Sentiment'].values

X_train, X_test, y_train, y_test = train_test_split(review, label, test_size=0.2)
X_train.size, y_train.size

tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')
tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)

word_index = tokenizer.word_index

with open('word_index.json', 'w') as fp:
  json.dump(word_index, fp)

X_train_sequence = tokenizer.texts_to_sequences(X_train)
X_test_sequence = tokenizer.texts_to_sequences(X_test)

X_train_padded = pad_sequences(X_train_sequence,
                               maxlen=20,
                               padding='post',
                               truncating='post')
X_test_paded = pad_sequences(X_test_sequence,
                             maxlen=20,
                             padding='post',
                             truncating='post')

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(
    learning_rate=0.0001), metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)

num_epochs = 100
history = model.fit(X_train_padded, 
                    y_train,
                    epochs=num_epochs,
                    validation_data=(X_test_paded, y_test),
                    verbose=2,
                    callbacks=[tensorboard_callback, es_callback])

import numpy as np

def get_predictions(text):
    sequence = tokenizer.texts_to_sequences([text])
    # pad the sequences
    sequence = pad_sequences(sequence, maxlen=20)
    # get the prediction
    prediction = model.predict(sequence)[0]
    return prediction, "Positive" if prediction > 0.5 else "Negative"

test_text = "Great music service,"
confidence, label = get_predictions(test_text)
print(confidence)
print(label)

def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()
  
plot_graphs(history, "accuracy")
plot_graphs(history, "loss")

model.save('model.h5')

!pip install -q tensorflowjs

!tensorflowjs_converter --input_format=keras model.h5 tfjs_model

